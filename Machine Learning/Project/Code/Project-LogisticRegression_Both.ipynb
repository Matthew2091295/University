{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size before bad entries removed:    2390\n",
      "size after bad entries removed:    2352\n"
     ]
    }
   ],
   "source": [
    "xlsx_file=Path('MLData_Trimmed2.xlsx')\n",
    "data = pd.read_excel(xlsx_file)\n",
    "data = data.to_numpy()\n",
    "\n",
    "#put voting status in last column for neatness\n",
    "data[:,[4, 7]] = data[:,[7, 4]]\n",
    "\n",
    "#current state of data [0]: respNo,  [1]: Urban/Rural,  [2]: Economic condition,  [3]: Discuss Politics?,  [4]: Education,  [5]: Request government action,  [6]: Views on corruption,  [7]: voted?\n",
    "\n",
    "#possible answers\n",
    "#urban/rural\n",
    "d1 = [\"Tribal\", \"Rural farm\", \"Rural\", \"Urban\"]\n",
    "#economic condition\n",
    "d2 = [\"Very good\", \"Fairly Good\", \"Fairly bad\", \"Very bad\", \"Don't know\", 'Neither good nor bad']\n",
    "#discuss politics\n",
    "d3 = [\"Never\",\"Occasionally\",\"Frequently\", \"Don't know\"]\n",
    "#education\n",
    "d4 = [\"No formal schooling\",\"Informal schooling only\",\"Some primary schooling\",\"Primary school completed\", \"Some secondary school / high school\" , \"Secondary school / high school completed\", \"Some university\", \"University completed\", \"Post-graduate\", \"Post-secondary qualifications, other than university\"]\n",
    "#requests government action\n",
    "d5 = [\"Don't know\",\"No, would never do this\",\"No, but would do if had the chance\",\"Yes, once or twice\",\"Yes, several times\",\"Yes, often\"]\n",
    "#views on corruption\n",
    "d6 = [\"Don't know\",\"Decreased a lot\",\"Decreased somewhat\",\"Stayed the same\", \"Increased somewhat\",\"Increased a lot\"]\n",
    "#voted?\n",
    "d7 = [\"1\",\"You voted in the elections\"]\n",
    "print(\"size before bad entries removed:   \", len(data))\n",
    "\n",
    "#np.delete(data,8,1)\n",
    "for i in range(len(data)-1,-1, -1):\n",
    "    currRow = data[i]\n",
    "    for j in range(0,len(d1)):\n",
    "        if(currRow[1] == d1[j]):\n",
    "            data[i,1] = j\n",
    "    for j in range(0,len(d2)):\n",
    "        if(currRow[2] == d2[j]):\n",
    "            data[i,2] = j\n",
    "    for j in range(0,len(d3)):\n",
    "        if(currRow[3] == d3[j]):\n",
    "            data[i,3] = j\n",
    "    for j in range(0,len(d4)):\n",
    "        if(currRow[4] == d4[j]):\n",
    "            data[i,4] = j\n",
    "    for j in range(0,len(d5)):\n",
    "        if(currRow[5] == d5[j]):\n",
    "            data[i,5] = j\n",
    "    for j in range(0,len(d6)):\n",
    "        if(currRow[6] == d6[j]):\n",
    "            data[i,6] = j\n",
    "    if(currRow[7] == d7[1]):\n",
    "        data[i,7] = 1\n",
    "    else:\n",
    "        data[i,7] = 0\n",
    "\n",
    "\n",
    "for i in range(len(data)-1, 0 , -1):\n",
    "    currRow = data[i]\n",
    "\n",
    "    for j in range(0,len(currRow)-1):\n",
    "        if(type(currRow[j]) != int):\n",
    "            data = np.delete(data, i, 0)\n",
    "        \n",
    "print(\"size after bad entries removed:   \", len(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls= 0\n",
    "os = 0\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    if(data[i][7] == 0):\n",
    "        os +=1\n",
    "    \n",
    "    if(data[i][7]==1):\n",
    "        ls +=1\n",
    "\n",
    "#perfectly balancing data\n",
    "for i in range(0, os):\n",
    "    ind = i\n",
    "    currRow = data[i]\n",
    "    if(currRow[7] == 0):\n",
    "       while(currRow[7] == 0):\n",
    "           ind = random.randint(0, len(data))\n",
    "           currRow = data[ind]\n",
    "    data = np.delete(data, ind, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up thetas, training, testing, validation\n",
    "theta=np.random.uniform(-0.5,0.5,6)\n",
    "CurrentData =copy.deepcopy(data)\n",
    "np.random.shuffle(CurrentData)\n",
    "tdnum = int(len(CurrentData)*0.6)\n",
    "vanum = int(len(CurrentData)*0.2)\n",
    "tenum = len(CurrentData)-(tdnum +vanum)\n",
    "training = CurrentData[0:tdnum,:]\n",
    "validation =CurrentData[tdnum:tdnum+vanum,:]\n",
    "testing = CurrentData[tdnum+vanum:len(data),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:    57.33990147783251 %\n",
      "validation accuracy:    62.42603550295858 %\n",
      "testing accuracy:    56.1764705882353 %\n",
      "training likelihood-error:    -741.7756617433637\n",
      "training likelihood-error:    -234.6062080161449\n",
      "training likelihood-error:    -250.01597551933548\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def logLikelihood(data, theta):\n",
    "    log_likelihood = 0\n",
    "    data_trimmed= data[:,1:7]\n",
    "\n",
    "    for i in range(0, len(data)):\n",
    "        currRow = data[i]\n",
    "        if(currRow[7] == 1):\n",
    "            dot = np.dot(theta,data_trimmed[i])\n",
    "            log_likelihood += math.log(sigmoid(dot))\n",
    "        else:\n",
    "            dot = np.dot(theta,data_trimmed[i])\n",
    "            log_likelihood += math.log(1-sigmoid(dot))\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def predict(data, theta,basis):\n",
    "    not1 = 0\n",
    "    data_trimmed= data[:,1:7]\n",
    "    True_Classes = data[:,7]\n",
    "    confusionMatrix = np.zeros((2,2))\n",
    "    for i in range(0,len(data)):\n",
    "        p_class1 = sigmoid(np.dot(theta,data_trimmed[i]**basis))\n",
    "        p_class0 = 1-p_class1\n",
    "        if(p_class1 < p_class0 and True_Classes[i] == 0):\n",
    "           confusionMatrix[0,0] += 1\n",
    "\n",
    "        if(p_class1 < p_class0 and True_Classes[i] == 1):\n",
    "           confusionMatrix[1,0] += 1\n",
    "\n",
    "        if(p_class1 > p_class0 and True_Classes[i] == 0):\n",
    "           confusionMatrix[0,1] += 1\n",
    "           not1+=1\n",
    "        if(p_class1 > p_class0 and True_Classes[i] == 1):\n",
    "           confusionMatrix[1,1] += 1\n",
    "\n",
    "\n",
    "    accuracy = (confusionMatrix[0,0] + confusionMatrix[1,1])/(confusionMatrix[0,1] + confusionMatrix[1,0] +confusionMatrix[0,0] + confusionMatrix[1,1])*100\n",
    "   \n",
    "    return accuracy,confusionMatrix\n",
    "        \n",
    "def GradientDescent(data, theta, rate, epochs,basis, regularisation):\n",
    "    lambdas = [0, regularisation,regularisation,regularisation,regularisation,regularisation]\n",
    "    data_trimmed= data[:,1:7]\n",
    "    True_Classes = data[:,7]\n",
    "    theta_old = theta\n",
    "    currEpoch=0\n",
    "    regthetas = copy.deepcopy(theta)\n",
    "    while True:\n",
    "        for i in range(0,len(data)):\n",
    "            if(True_Classes[i] == 0):\n",
    "                theta = theta-rate*(sigmoid(np.dot(theta,data_trimmed[i]**basis))-0 +lambdas*theta)\n",
    "                \n",
    "            if(True_Classes[i] == 1):\n",
    "                theta = theta-rate*(sigmoid(np.dot(theta,data_trimmed[i]**basis))-1 +lambdas*theta)\n",
    "                \n",
    "            for i in range(0,len(theta)):\n",
    "                theta[i] = round(theta[i],8)\n",
    "\n",
    "        currEpoch +=1\n",
    "        #print(currEpoch)\n",
    "        if(np.linalg.norm(abs(theta_old-theta))< 0.000005 or currEpoch == epochs):\n",
    "\n",
    "            break\n",
    "        theta_old = theta\n",
    "    return theta\n",
    "\n",
    "basis = [0, 1, 1, 2, 1, 1]\n",
    "theta = GradientDescent(training,theta,0.00001, 100,basis, 0)\n",
    "\n",
    "print(\"training accuracy:   \",predict(training,theta, basis)[0], \"%\")\n",
    "print(\"validation accuracy:   \",predict(validation,theta, basis)[0], \"%\")\n",
    "print(\"testing accuracy:   \",predict(testing,theta, basis)[0], \"%\")\n",
    "print(\"training likelihood-error:   \", logLikelihood(training,theta))\n",
    "print(\"training likelihood-error:   \",logLikelihood(validation,theta))\n",
    "print(\"training likelihood-error:   \",logLikelihood(testing,theta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : \n",
      " [[101. 295.]\n",
      " [138. 481.]]\n",
      "Training  classification Error:   0.4266009852216749\n",
      "Training  False alarm:  0.5774058577405857\n",
      "Training  miss:  0.3801546391752577\n",
      "Training  recall:  0.6198453608247423\n",
      "Training  precision:  0.777059773828756\n",
      "Vlaidation : \n",
      " [[ 40.  89.]\n",
      " [ 38. 171.]]\n",
      "Vlaidation  classification Error:   0.3757396449704142\n",
      "Vlaidation  False alarm:  0.48717948717948717\n",
      "Vlaidation  miss:  0.3423076923076923\n",
      "Vlaidation  recall:  0.6576923076923077\n",
      "Vlaidation  precision:  0.8181818181818182\n",
      "Testing : \n",
      " [[ 35.  99.]\n",
      " [ 50. 156.]]\n",
      "Testing  classification Error:   0.43823529411764706\n",
      "Testing  False alarm:  0.5882352941176471\n",
      "Testing  miss:  0.38823529411764707\n",
      "Testing  recall:  0.611764705882353\n",
      "Testing  precision:  0.7572815533980582\n"
     ]
    }
   ],
   "source": [
    "def getMatrixCalculations(confmat, datasetname):\n",
    "    print(datasetname,\": \\n\",confmat)\n",
    "    classerror = (confmat[1,0]+confmat[0,1])/(confmat[1,0]+confmat[0,1]+confmat[1,1]+confmat[0,0])\n",
    "    falsealarm = (confmat[1,0])/(confmat[1,0]+confmat[0,0])\n",
    "    miss = (confmat[0,1])/(confmat[1,1]+confmat[0,1])\n",
    "    recall = (confmat[1,1])/(confmat[0,1]+confmat[1,1])\n",
    "    precision = (confmat[1,1])/(confmat[1,0]+confmat[1,1])\n",
    "    print(datasetname, \" classification Error:  \", classerror)\n",
    "    print(datasetname, \" False alarm: \" , falsealarm)\n",
    "    print(datasetname, \" miss: \", miss)\n",
    "    print(datasetname, \" recall: \", recall)\n",
    "    print(datasetname, \" precision: \", precision)\n",
    "\n",
    "\n",
    "getMatrixCalculations(predict(training,theta, basis)[1], \"Training\")\n",
    "getMatrixCalculations(predict(validation,theta, basis)[1], \"Vlaidation\")\n",
    "getMatrixCalculations(predict(testing,theta, basis)[1], \"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
